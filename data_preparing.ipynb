{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:35:38.974404Z",
     "iopub.status.busy": "2024-06-26T09:35:38.973496Z",
     "iopub.status.idle": "2024-06-26T09:35:52.642110Z",
     "shell.execute_reply": "2024-06-26T09:35:52.641154Z",
     "shell.execute_reply.started": "2024-06-26T09:35:38.974363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_colwidth = 1000\n",
    "tqdm.pandas()\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Add, Concatenate, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, LSTM, Reshape\n",
    "from keras.layers import BatchNormalization, SeparableConv2D, DepthwiseConv2D, LeakyReLU, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Make sure we are able to handle large datasets\n",
    "import resource\n",
    "\n",
    "low, high = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (high, high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize constants and lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:35:54.402083Z",
     "iopub.status.busy": "2024-06-26T09:35:54.401798Z",
     "iopub.status.idle": "2024-06-26T09:35:54.410147Z",
     "shell.execute_reply": "2024-06-26T09:35:54.409152Z",
     "shell.execute_reply.started": "2024-06-26T09:35:54.402058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "activity_map = {'c0': 'Safe driving',\n",
    "                'c1': 'Texting - right',\n",
    "                'c2': 'Talking on the phone - right',\n",
    "                'c3': 'Texting - left',\n",
    "                'c4': 'Talking on the phone - left',\n",
    "                'c5': 'Operating the radio',\n",
    "                'c6': 'Drinking',\n",
    "                'c7': 'Reaching behind',\n",
    "                'c8': 'Hair and makeup',\n",
    "                'c9': 'Talking to passenger'}\n",
    "class_mapping = {'c0': 0,\n",
    "                'c1': 1,\n",
    "                'c2': 2,\n",
    "                'c3': 3,\n",
    "                'c4': 4,\n",
    "                'c5': 5,\n",
    "                'c6': 6,\n",
    "                'c7': 7,\n",
    "                'c8': 8,\n",
    "                'c9': 9}\n",
    "\n",
    "# Algorithm hyperparameters\n",
    "num_epochs = 70\n",
    "batch_size = 64\n",
    "width = 256\n",
    "temperature = 0.1\n",
    "\n",
    "# Stronger augmentations for contrastive, weaker ones for supervised training\n",
    "contrastive_augmentation = {\n",
    "    \"min_area\": 0.75, \n",
    "    \"brightness\": 0.5, \n",
    "    \"jitter\": 0.2\n",
    "}\n",
    "\n",
    "classification_augmentation = {\n",
    "    \"min_area\": 0.8,\n",
    "    \"brightness\": 0.3,\n",
    "    \"jitter\": 0.1,\n",
    "}\n",
    "\n",
    "IMG_DIM = 208\n",
    "CHANNEL_SIZE = 3\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data preprocess**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Fetching training driver_imgs_list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:35:54.436315Z",
     "iopub.status.busy": "2024-06-26T09:35:54.436042Z",
     "iopub.status.idle": "2024-06-26T09:35:54.503934Z",
     "shell.execute_reply": "2024-06-26T09:35:54.502959Z",
     "shell.execute_reply.started": "2024-06-26T09:35:54.436292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dir_path = '/kaggle/input/state-farm-distracted-driver-detection'\n",
    "\n",
    "driver_imgs_list = pd.read_csv(os.path.join(dir_path, \"driver_imgs_list.csv\"))\n",
    "driver_imgs_list['class'] = driver_imgs_list['classname'].replace(activity_map)\n",
    "driver_imgs_list.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Fetching the list of training image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:35:54.505539Z",
     "iopub.status.busy": "2024-06-26T09:35:54.505214Z",
     "iopub.status.idle": "2024-06-26T09:35:57.010553Z",
     "shell.execute_reply": "2024-06-26T09:35:57.009670Z",
     "shell.execute_reply.started": "2024-06-26T09:35:54.505511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "list_train_img = glob.glob(os.path.join(dir_path, \"imgs\", \"train\", \"*\",  \"*.jpg\"))\n",
    "print(\"Total number of Train Images is -------->\", len(list_train_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Adding image path in the data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:35:57.011754Z",
     "iopub.status.busy": "2024-06-26T09:35:57.011509Z",
     "iopub.status.idle": "2024-06-26T09:36:32.432787Z",
     "shell.execute_reply": "2024-06-26T09:36:32.431862Z",
     "shell.execute_reply.started": "2024-06-26T09:35:57.011732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "driver_imgs_list['ImgPath'] = driver_imgs_list['img'].progress_apply(lambda x: [i for i in  list_train_img if x in i][0])\n",
    "\n",
    "df = driver_imgs_list.copy()\n",
    "\n",
    "del driver_imgs_list, list_train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:32.434228Z",
     "iopub.status.busy": "2024-06-26T09:36:32.433884Z",
     "iopub.status.idle": "2024-06-26T09:36:32.444417Z",
     "shell.execute_reply": "2024-06-26T09:36:32.443478Z",
     "shell.execute_reply.started": "2024-06-26T09:36:32.434174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:32.445784Z",
     "iopub.status.busy": "2024-06-26T09:36:32.445534Z",
     "iopub.status.idle": "2024-06-26T09:36:32.483628Z",
     "shell.execute_reply": "2024-06-26T09:36:32.482782Z",
     "shell.execute_reply.started": "2024-06-26T09:36:32.445761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total number of rows\n",
    "total_rows = len(df)\n",
    "\n",
    "# Divide the total number of rows by 2 to get the number of rows to keep\n",
    "rows_to_keep = int((total_rows / 10) // 1.5)\n",
    "\n",
    "# Group the DataFrame by column 'A' and sample the desired number of rows from each group\n",
    "new_df = df.groupby('classname', group_keys=False).sample(n=rows_to_keep)\n",
    "\n",
    "new_df.head()\n",
    "\n",
    "del df\n",
    "df = new_df.copy()\n",
    "df.head()\n",
    "del new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:32.494557Z",
     "iopub.status.busy": "2024-06-26T09:36:32.494222Z",
     "iopub.status.idle": "2024-06-26T09:36:32.520813Z",
     "shell.execute_reply": "2024-06-26T09:36:32.519832Z",
     "shell.execute_reply.started": "2024-06-26T09:36:32.494527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['label'] = df['classname'].apply(lambda x: class_mapping[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:32.522879Z",
     "iopub.status.busy": "2024-06-26T09:36:32.522354Z",
     "iopub.status.idle": "2024-06-26T09:36:33.110395Z",
     "shell.execute_reply": "2024-06-26T09:36:33.109064Z",
     "shell.execute_reply.started": "2024-06-26T09:36:32.522846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# BatPlot and Piechart\n",
    "class_freq_count = df.classname.value_counts()\n",
    "\n",
    "class_freq_count.plot(kind='bar', label='index')\n",
    "plt.title('Sample Per Class')\n",
    "plt.show()\n",
    "\n",
    "plt.pie(class_freq_count, autopct='%1.1f%%', shadow=True, labels=activity_map.values())\n",
    "plt.title('Sample % per class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Creating Function which will plot image by using their class and the imagePath**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:33.112491Z",
     "iopub.status.busy": "2024-06-26T09:36:33.112010Z",
     "iopub.status.idle": "2024-06-26T09:36:33.123624Z",
     "shell.execute_reply": "2024-06-26T09:36:33.122501Z",
     "shell.execute_reply.started": "2024-06-26T09:36:33.112443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def draw_driver(imgs, df, classId='c0'):\n",
    "    fig, axis = plt.subplots(2, 3, figsize=(20, 7))\n",
    "    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n",
    "        imgPath = os.path.join(dir_path, \"imgs\", \"train\", f\"{classId}/{row['img']}\")\n",
    "        row = idnx // 3\n",
    "        col = idnx % 3\n",
    "        img = load_img(imgPath)\n",
    "        #         img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        plt.imshow(img)\n",
    "        axis[row, col].imshow(img)\n",
    "    plt.suptitle(activity_map[classId])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:33.125888Z",
     "iopub.status.busy": "2024-06-26T09:36:33.125120Z",
     "iopub.status.idle": "2024-06-26T09:36:34.742237Z",
     "shell.execute_reply": "2024-06-26T09:36:34.741190Z",
     "shell.execute_reply.started": "2024-06-26T09:36:33.125844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "draw_driver(df[df.classname == 'c0'].head(6), df, classId='c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:34.743798Z",
     "iopub.status.busy": "2024-06-26T09:36:34.743478Z",
     "iopub.status.idle": "2024-06-26T09:36:36.324850Z",
     "shell.execute_reply": "2024-06-26T09:36:36.323881Z",
     "shell.execute_reply.started": "2024-06-26T09:36:34.743771Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "draw_driver(df[df.classname == 'c1'].head(6), df, classId='c1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pretain - Finetune split:**\n",
    "- Pretrain 0.8 - Finetune 0.2\n",
    "- Pretrain: 0.8 train, 0.2 val\n",
    "- Pretrain_train: 0.5 unlabeled, 0.5 labeled\n",
    "- Finetune: 0.8 train, 0.2 val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:36.352301Z",
     "iopub.status.busy": "2024-06-26T09:36:36.351974Z",
     "iopub.status.idle": "2024-06-26T09:36:36.420902Z",
     "shell.execute_reply": "2024-06-26T09:36:36.420188Z",
     "shell.execute_reply.started": "2024-06-26T09:36:36.352268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# pretrain and finetune split\n",
    "pretrain_dataset, finetune_dataset = train_test_split(df ,test_size = 0.2 , random_state = 42, shuffle = True,\n",
    "                                               stratify = df['class'])\n",
    "\n",
    "# pretrain split\n",
    "pretrain_train, pretrain_val = train_test_split(pretrain_dataset ,test_size = 0.2 , random_state = 42, shuffle = True,\n",
    "                                               stratify = pretrain_dataset['class'])\n",
    "\n",
    "pretrain_unlabeled, pretrain_labeled = train_test_split(pretrain_train ,test_size = 0.5 , random_state = 42, shuffle = True,\n",
    "                                               stratify = pretrain_train['class'])\n",
    "\n",
    "# finetune split\n",
    "\n",
    "finetune_train, finetune_val = train_test_split(finetune_dataset, test_size = 0.2, random_state = 42, shuffle = True,\n",
    "                                              stratify = finetune_dataset['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:36.422175Z",
     "iopub.status.busy": "2024-06-26T09:36:36.421919Z",
     "iopub.status.idle": "2024-06-26T09:36:36.427107Z",
     "shell.execute_reply": "2024-06-26T09:36:36.426214Z",
     "shell.execute_reply.started": "2024-06-26T09:36:36.422152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(pretrain_train))\n",
    "print(len(pretrain_val))\n",
    "print(len(finetune_train))\n",
    "print(len(finetune_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:36.428517Z",
     "iopub.status.busy": "2024-06-26T09:36:36.428290Z",
     "iopub.status.idle": "2024-06-26T09:36:36.435921Z",
     "shell.execute_reply": "2024-06-26T09:36:36.435174Z",
     "shell.execute_reply.started": "2024-06-26T09:36:36.428497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data generators\n",
    "image_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:36.437505Z",
     "iopub.status.busy": "2024-06-26T09:36:36.437166Z",
     "iopub.status.idle": "2024-06-26T09:36:41.109744Z",
     "shell.execute_reply": "2024-06-26T09:36:41.108929Z",
     "shell.execute_reply.started": "2024-06-26T09:36:36.437475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "finetune_train_dataset = image_datagen.flow_from_dataframe(\n",
    "                        dataframe = finetune_train,\n",
    "                        x_col = 'ImgPath',\n",
    "                        y_col = 'class',\n",
    "                        target_size=(IMG_DIM,IMG_DIM),\n",
    "                        class_mode = 'categorical',\n",
    "                        batch_size= 64)\n",
    "\n",
    "finetune_val_dataset = image_datagen.flow_from_dataframe(\n",
    "                dataframe = finetune_val,\n",
    "                x_col = 'ImgPath',\n",
    "                y_col = 'class',\n",
    "                target_size = (IMG_DIM, IMG_DIM),\n",
    "                class_mode = 'categorical',\n",
    "                batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Function to conver from pd.DataFrame to Tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:41.111488Z",
     "iopub.status.busy": "2024-06-26T09:36:41.111064Z",
     "iopub.status.idle": "2024-06-26T09:36:41.120665Z",
     "shell.execute_reply": "2024-06-26T09:36:41.119955Z",
     "shell.execute_reply.started": "2024-06-26T09:36:41.111449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_size = (IMG_DIM, IMG_DIM)\n",
    "def data_conversion(df):\n",
    "    # Down image datas from the directory and change into numpy_array datatype \n",
    "    \n",
    "    resized_images = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Read image from directory\n",
    "        img_path = row['ImgPath']\n",
    "        original_image = plt.imread(img_path)\n",
    "\n",
    "        # Resize image\n",
    "        new_size = (IMG_DIM, IMG_DIM)  # New size (width, height)\n",
    "        resized_image = np.array(Image.fromarray(original_image).resize(new_size))\n",
    "\n",
    "        # Add resized img to array\n",
    "        resized_images.append(resized_image)\n",
    "\n",
    "    # Chang array to NumPy_array\n",
    "    X = np.array(resized_images)\n",
    "\n",
    "    # Change column 'label' into y\n",
    "    y = tf.convert_to_tensor(df['label'])\n",
    "\n",
    "    # Create tf.data.Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:36:41.122514Z",
     "iopub.status.busy": "2024-06-26T09:36:41.122148Z",
     "iopub.status.idle": "2024-06-26T09:39:12.357678Z",
     "shell.execute_reply": "2024-06-26T09:39:12.356737Z",
     "shell.execute_reply.started": "2024-06-26T09:36:41.122482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pretrain_labeled_dataset = data_conversion(pretrain_labeled)\n",
    "pretrain_unlabeled_dataset = data_conversion(pretrain_unlabeled)\n",
    "pretrain_val_dataset = data_conversion(pretrain_val)\n",
    "print(type(pretrain_labeled_dataset))\n",
    "print(type(pretrain_unlabeled_dataset))\n",
    "print(type(pretrain_val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Merging pretrain_labeled and pretrain_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:12.359156Z",
     "iopub.status.busy": "2024-06-26T09:39:12.358873Z",
     "iopub.status.idle": "2024-06-26T09:39:12.370334Z",
     "shell.execute_reply": "2024-06-26T09:39:12.369594Z",
     "shell.execute_reply.started": "2024-06-26T09:39:12.359131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.zip(\n",
    "        (pretrain_unlabeled_dataset, pretrain_labeled_dataset)\n",
    "    ).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:12.371649Z",
     "iopub.status.busy": "2024-06-26T09:39:12.371358Z",
     "iopub.status.idle": "2024-06-26T09:39:12.383645Z",
     "shell.execute_reply": "2024-06-26T09:39:12.382728Z",
     "shell.execute_reply.started": "2024-06-26T09:39:12.371624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:12.385099Z",
     "iopub.status.busy": "2024-06-26T09:39:12.384816Z",
     "iopub.status.idle": "2024-06-26T09:39:13.308002Z",
     "shell.execute_reply": "2024-06-26T09:39:13.307009Z",
     "shell.execute_reply.started": "2024-06-26T09:39:12.385074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img = next(iter(train_dataset))[0][1]\n",
    "print(img.shape)\n",
    "print(type(img))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:13.309598Z",
     "iopub.status.busy": "2024-06-26T09:39:13.309313Z",
     "iopub.status.idle": "2024-06-26T09:39:13.547021Z",
     "shell.execute_reply": "2024-06-26T09:39:13.546071Z",
     "shell.execute_reply.started": "2024-06-26T09:39:13.309572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img = next(iter(pretrain_val_dataset))\n",
    "print(type(img))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:13.555730Z",
     "iopub.status.busy": "2024-06-26T09:39:13.555174Z",
     "iopub.status.idle": "2024-06-26T09:39:17.452359Z",
     "shell.execute_reply": "2024-06-26T09:39:17.451423Z",
     "shell.execute_reply.started": "2024-06-26T09:39:13.555699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomColorAffine(layers.Layer):\n",
    "    def __init__(self, brightness=0, jitter=0, **kwargs):\n",
    "        super(RandomColorAffine, self).__init__(**kwargs)\n",
    "\n",
    "        self.brightness = brightness\n",
    "        self.jitter = jitter\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(RandomColorAffine, self).get_config()\n",
    "        config. update({\"brightness\": self.brightness, \"jitter\": self.jitter})\n",
    "        return config\n",
    "\n",
    "    def call(self, images, training=None):\n",
    "        if training:\n",
    "            batch_size = tf.shape(images)[0]\n",
    "\n",
    "            brightness_scales = 1 + tf.random.uniform(\n",
    "                (batch_size, 1, 1, 1), minval=-self.brightness, maxval=self.brightness\n",
    "            )\n",
    "            jitter_matrices = tf.random.uniform(\n",
    "                (batch_size, 1, 3, 3), minval=-self.jitter, maxval=self.jitter\n",
    "            )\n",
    "\n",
    "            color_transforms = (\n",
    "                tf.eye(3, batch_shape=[batch_size, 1]) * brightness_scales\n",
    "                + jitter_matrices\n",
    "            )\n",
    "            images = tf.clip_by_value(tf.matmul(images, color_transforms), 0, 1)\n",
    "        return images\n",
    "\n",
    "\n",
    "\n",
    "# Image augmentation module\n",
    "def get_augmenter(min_area, brightness, jitter):\n",
    "    zoom_factor = 1.0 - math.sqrt(min_area)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Rescaling(1 / 255),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n",
    "            layers.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n",
    "            RandomColorAffine(brightness, jitter),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def visualize_augmentations(num_images):\n",
    "    # Sample a batch from a dataset\n",
    "    images = next(iter(train_dataset))[0][0][:num_images]\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmented_images = zip(\n",
    "        images,\n",
    "        get_augmenter(**classification_augmentation)(images),\n",
    "        get_augmenter(**contrastive_augmentation)(images),\n",
    "        get_augmenter(**contrastive_augmentation)(images),\n",
    "    )\n",
    "    row_titles = [\n",
    "        \"Original:\",\n",
    "        \"Weakly augmented:\",\n",
    "        \"Strongly augmented 1st:\",\n",
    "        \"Strongly augmented 2nd:\",\n",
    "    ]\n",
    "    plt.figure(figsize=(12, 8), dpi=100)\n",
    "    for column, image_row in enumerate(augmented_images):\n",
    "        for row, image in enumerate(image_row):\n",
    "            plt.subplot(4, num_images, row * num_images + column + 1)\n",
    "            plt.imshow(image)\n",
    "            if column == 0:\n",
    "                plt.title(row_titles[row], loc=\"left\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "visualize_augmentations(num_images=4)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868335,
     "sourceId": 5048,
     "sourceType": "competition"
    },
    {
     "datasetId": 5006073,
     "sourceId": 8411180,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
