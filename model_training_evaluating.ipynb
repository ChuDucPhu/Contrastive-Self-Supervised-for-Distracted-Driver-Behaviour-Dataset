{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:35:38.974404Z",
     "iopub.status.busy": "2024-06-26T09:35:38.973496Z",
     "iopub.status.idle": "2024-06-26T09:35:52.642110Z",
     "shell.execute_reply": "2024-06-26T09:35:52.641154Z",
     "shell.execute_reply.started": "2024-06-26T09:35:38.974363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "pd.options.display.max_colwidth = 1000\n",
    "tqdm.pandas()\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Add, Concatenate, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D, LSTM, Reshape\n",
    "from keras.layers import BatchNormalization, SeparableConv2D, DepthwiseConv2D, LeakyReLU, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Make sure we are able to handle large datasets\n",
    "import resource\n",
    "\n",
    "low, high = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (high, high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize constants and lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:35:54.402083Z",
     "iopub.status.busy": "2024-06-26T09:35:54.401798Z",
     "iopub.status.idle": "2024-06-26T09:35:54.410147Z",
     "shell.execute_reply": "2024-06-26T09:35:54.409152Z",
     "shell.execute_reply.started": "2024-06-26T09:35:54.402058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "activity_map = {'c0': 'Safe driving',\n",
    "                'c1': 'Texting - right',\n",
    "                'c2': 'Talking on the phone - right',\n",
    "                'c3': 'Texting - left',\n",
    "                'c4': 'Talking on the phone - left',\n",
    "                'c5': 'Operating the radio',\n",
    "                'c6': 'Drinking',\n",
    "                'c7': 'Reaching behind',\n",
    "                'c8': 'Hair and makeup',\n",
    "                'c9': 'Talking to passenger'}\n",
    "class_mapping = {'c0': 0,\n",
    "                'c1': 1,\n",
    "                'c2': 2,\n",
    "                'c3': 3,\n",
    "                'c4': 4,\n",
    "                'c5': 5,\n",
    "                'c6': 6,\n",
    "                'c7': 7,\n",
    "                'c8': 8,\n",
    "                'c9': 9}\n",
    "\n",
    "# Algorithm hyperparameters\n",
    "num_epochs = 70\n",
    "batch_size = 64\n",
    "width = 256\n",
    "temperature = 0.1\n",
    "\n",
    "# Stronger augmentations for contrastive, weaker ones for supervised training\n",
    "contrastive_augmentation = {\n",
    "    \"min_area\": 0.75, \n",
    "    \"brightness\": 0.5, \n",
    "    \"jitter\": 0.2\n",
    "}\n",
    "\n",
    "classification_augmentation = {\n",
    "    \"min_area\": 0.8,\n",
    "    \"brightness\": 0.3,\n",
    "    \"jitter\": 0.1,\n",
    "}\n",
    "\n",
    "IMG_DIM = 208\n",
    "CHANNEL_SIZE = 3\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Encoder Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:17.454444Z",
     "iopub.status.busy": "2024-06-26T09:39:17.453925Z",
     "iopub.status.idle": "2024-06-26T09:39:17.478042Z",
     "shell.execute_reply": "2024-06-26T09:39:17.477042Z",
     "shell.execute_reply.started": "2024-06-26T09:39:17.454411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import datasets,models,layers\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "l2_reg = 0\n",
    "\n",
    "# Define model\n",
    "def Resnet_Inception_HRNN():\n",
    "  inputs = Input((IMG_DIM, IMG_DIM, CHANNEL_SIZE))\n",
    "\n",
    "  # Resnet\n",
    "  r1 = Conv2D(3, kernel_size=(5,5), activation='relu', padding='same', kernel_regularizer = l2(0.001))(inputs)\n",
    "  r2 = BatchNormalization()(r1)\n",
    "  r3 = SeparableConv2D(3, kernel_size=(5,5), activation='relu', padding='same')(r2)\n",
    "  r3 = BatchNormalization()(r3)\n",
    "  #Add result with input\n",
    "  r5 = Add()([r3, inputs])\n",
    "  r6 = Activation('relu')(r5)\n",
    "  r7 = AveragePooling2D(pool_size=(2,2), strides=(2,2), padding='same')(r6)\n",
    "\n",
    "  # Cải tiến\n",
    "  r7 = SeparableConv2D(3, kernel_size=(5,5), strides = (2,2) ,activation='relu', padding='same')(r7)\n",
    "  r7 = BatchNormalization()(r7)\n",
    "  r7 = SeparableConv2D(16, kernel_size=(5,5), strides = (2,2) ,activation='relu', padding='same')(r7)\n",
    "  r7 = BatchNormalization()(r7)\n",
    "  r7 = SeparableConv2D(16, kernel_size=(5,5), strides = (2,2) ,activation='relu', padding='same')(r7)\n",
    "  r7 = BatchNormalization()(r7)\n",
    "  # Cải tiến\n",
    "\n",
    "  r7 = GlobalAveragePooling2D()(r7)\n",
    "\n",
    "\n",
    "  # Inception module\n",
    "  # Branch 1: 1x1 Conv + 5x5 Conv\n",
    "  b1 = Conv2D(7, kernel_size = (1,1), activation='relu', padding='same', kernel_regularizer = l2(0.001))(inputs)\n",
    "  b1 = BatchNormalization()(b1)\n",
    "  b1 = SeparableConv2D(7, kernel_size = (5,5), activation='relu', padding='same')(b1)\n",
    "\n",
    "  # Branch 2: 1x1 Conv + 5x5 Conv\n",
    "  b2 = Conv2D(7, kernel_size = (1,1), activation='relu', padding='same', kernel_regularizer = l2(0.001))(inputs)\n",
    "  b2 = BatchNormalization()(b2)\n",
    "  b2 = SeparableConv2D(7, kernel_size = (5,5), activation='relu', padding='same')(b2)\n",
    "\n",
    "  # Branch 3 :3x3 MaxPooling + 1x1 Conv\n",
    "  b3 = MaxPooling2D(pool_size=(3,3), strides = (1,1), padding='same')(inputs)\n",
    "  b3 = SeparableConv2D(7, kernel_size = (1,1), activation='relu', padding='same')(b3)\n",
    "  b3 = BatchNormalization()(b3)\n",
    "\n",
    "  # Concatenate 3 branches:\n",
    "  b4 = Concatenate(axis=-1)([b1, b2, b3])\n",
    "\n",
    "  #Cải tiến\n",
    "  b4 = SeparableConv2D(16, kernel_size = (3,3), strides = (2,2), activation='relu', padding='same')(b4)\n",
    "  b4 = BatchNormalization()(b4)\n",
    "  b4 = SeparableConv2D(32, kernel_size = (3,3), strides = (2,2), activation='relu', padding='same')(b4)\n",
    "  b4 = BatchNormalization()(b4)\n",
    "  b4 = SeparableConv2D(32, kernel_size = (3,3), strides = (2,2), activation='relu', padding='same')(b4)\n",
    "  b4 = BatchNormalization()(b4)\n",
    "  #Cải tiến\n",
    "  b4 = GlobalAveragePooling2D()(b4)\n",
    "\n",
    "\n",
    "  #HRRN block\n",
    "  input_shape = (26,1248)\n",
    "  LSTM_UNITS = 80\n",
    "  # Average Pooling\n",
    "  h = AveragePooling2D(pool_size=(3,3), strides=(2,2), padding='same')(inputs)\n",
    "  h = Reshape(input_shape)(h)\n",
    "  h = LSTM(LSTM_UNITS, return_sequences=True, input_shape=input_shape)(h)\n",
    "  h = LSTM(LSTM_UNITS)(h)\n",
    "\n",
    "  concat = Concatenate(axis=-1)([b4, r7, h])\n",
    "\n",
    "  x = Dense(80, activation='relu')(concat)\n",
    "  x = Dropout(0.2)(x)\n",
    "  x = Dense(80, activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  outputs = Dense(256, activation='relu')(x)\n",
    "\n",
    "  model = Model(inputs = inputs, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:17.479704Z",
     "iopub.status.busy": "2024-06-26T09:39:17.479289Z",
     "iopub.status.idle": "2024-06-26T09:39:18.007956Z",
     "shell.execute_reply": "2024-06-26T09:39:18.007009Z",
     "shell.execute_reply.started": "2024-06-26T09:39:17.479670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Resnet_Inception_HRNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:18.009476Z",
     "iopub.status.busy": "2024-06-26T09:39:18.009089Z",
     "iopub.status.idle": "2024-06-26T09:39:18.014022Z",
     "shell.execute_reply": "2024-06-26T09:39:18.012977Z",
     "shell.execute_reply.started": "2024-06-26T09:39:18.009449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_encoder():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            model\n",
    "        ],\n",
    "        name=\"encoder\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Supervised baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:39:18.015751Z",
     "iopub.status.busy": "2024-06-26T09:39:18.015085Z",
     "iopub.status.idle": "2024-06-26T09:54:55.424420Z",
     "shell.execute_reply": "2024-06-26T09:54:55.423439Z",
     "shell.execute_reply.started": "2024-06-26T09:39:18.015723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Baseline supervised training with random initialization\n",
    "baseline_model = keras.Sequential(\n",
    "    [\n",
    "        get_augmenter(**classification_augmentation),\n",
    "        get_encoder(),\n",
    "        layers.Dense(10),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ],\n",
    "    name=\"baseline_model\",\n",
    ")\n",
    "baseline_model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=keras.optimizers.Adam(),\n",
    "                metrics=['acc'])\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    finetune_train_dataset, epochs=num_epochs, validation_data=finetune_val_dataset\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(baseline_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contrastive model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:54:55.437066Z",
     "iopub.status.busy": "2024-06-26T09:54:55.436779Z",
     "iopub.status.idle": "2024-06-26T09:54:55.562023Z",
     "shell.execute_reply": "2024-06-26T09:54:55.561204Z",
     "shell.execute_reply.started": "2024-06-26T09:54:55.437040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the contrastive model with model-subclassing\n",
    "class ContrastiveModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.contrastive_augmenter = get_augmenter(**contrastive_augmentation)\n",
    "        self.classification_augmenter = get_augmenter(**classification_augmentation)\n",
    "        self.encoder = get_encoder()\n",
    "        # Non-linear MLP as projection head\n",
    "        self.projection_head = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(width,)),\n",
    "                layers.Dense(width, activation=\"relu\"),\n",
    "                layers.Dense(width),\n",
    "            ],\n",
    "            name=\"Project_Head\",\n",
    "        )\n",
    "        # Single dense layer for linear probing\n",
    "        self.linear_probe = keras.Sequential(\n",
    "            [layers.Input(shape=(width,)), layers.Dense(10)], name=\"linear_probe\"\n",
    "        )\n",
    "\n",
    "        # self.encoder.summary()\n",
    "        self.projection_head.summary()\n",
    "        self.linear_probe.summary()\n",
    "\n",
    "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "        self.probe_optimizer = probe_optimizer\n",
    "\n",
    "        # self.contrastive_loss will be defined as a method\n",
    "        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy(\n",
    "            name=\"c_acc\"\n",
    "        )\n",
    "        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n",
    "        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy(name=\"p_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.contrastive_accuracy,\n",
    "            self.probe_loss_tracker,\n",
    "            self.probe_accuracy,\n",
    "        ]\n",
    "\n",
    "    def contrastive_loss(self, projections_1, projections_2):\n",
    "        # InfoNCE loss (information noise-contrastive estimation)\n",
    "        # NT-Xent loss (normalized temperature-scaled cross entropy)\n",
    "\n",
    "        # Cosine similarity: the dot product of the l2-normalized feature vectors\n",
    "        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n",
    "        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n",
    "        similarities = (\n",
    "            tf.matmul(projections_1, projections_2, transpose_b=True) / self.temperature\n",
    "        )\n",
    "\n",
    "        # The similarity between the representations of two augmented views of the\n",
    "        # same image should be higher than their similarity with other views\n",
    "        batch_size = tf.shape(projections_1)[0]\n",
    "        contrastive_labels = tf.range(batch_size)\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n",
    "        self.contrastive_accuracy.update_state(\n",
    "            contrastive_labels, tf.transpose(similarities)\n",
    "        )\n",
    "\n",
    "        # The temperature-scaled similarities are used as logits for cross-entropy\n",
    "        # a symmetrized version of the loss is used here\n",
    "        loss_1_2 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, similarities, from_logits=True\n",
    "        )\n",
    "        loss_2_1 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, tf.transpose(similarities), from_logits=True\n",
    "        )\n",
    "        return (loss_1_2 + loss_2_1) / 2\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (unlabeled_images, _), (labeled_images, labels) = data\n",
    "\n",
    "        # Both labeled and unlabeled images are used, without labels\n",
    "        images = tf.concat((unlabeled_images, labeled_images), axis=0)\n",
    "        # Each image is augmented twice, differently\n",
    "        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n",
    "        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_1 = self.encoder(augmented_images_1, training=True)\n",
    "            features_2 = self.encoder(augmented_images_2, training=True)\n",
    "            # The representations are passed through a projection mlp\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "\n",
    "        # Labels are only used in evaluation for an on-the-fly logistic regression\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=True\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            # the encoder is used in inference mode here to avoid regularization\n",
    "            # and updating the batch normalization parameters if they are used\n",
    "            features = self.encoder(preprocessed_images, training=False)\n",
    "            class_logits = self.linear_probe(features, training=True)\n",
    "            probe_loss = self.probe_loss(labels, class_logits)\n",
    "        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n",
    "        self.probe_optimizer.apply_gradients(\n",
    "            zip(gradients, self.linear_probe.trainable_weights)\n",
    "        )\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        labeled_images, labels = data\n",
    "\n",
    "        # For testing, the components are used with a training=False flag\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=False\n",
    "        )\n",
    "        features = self.encoder(preprocessed_images, training=False)\n",
    "        class_logits = self.linear_probe(features, training=False)\n",
    "        probe_loss = self.probe_loss(labels, class_logits)\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        # Only the probe metrics are logged at test time\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}\n",
    "\n",
    "\n",
    "# Contrastive pretraining\n",
    "pretraining_model = ContrastiveModel()\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(),\n",
    "    probe_optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "pretraining_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T09:54:55.563695Z",
     "iopub.status.busy": "2024-06-26T09:54:55.563273Z",
     "iopub.status.idle": "2024-06-26T11:23:12.989087Z",
     "shell.execute_reply": "2024-06-26T11:23:12.988123Z",
     "shell.execute_reply.started": "2024-06-26T09:54:55.563661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pretraining_history = pretraining_model.fit(\n",
    "    train_dataset, epochs=num_epochs, validation_data=pretrain_val_dataset\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(pretraining_history.history[\"val_p_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Supervised finetuning of pretrain model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:12.990597Z",
     "iopub.status.busy": "2024-06-26T11:23:12.990299Z",
     "iopub.status.idle": "2024-06-26T11:23:12.999259Z",
     "shell.execute_reply": "2024-06-26T11:23:12.998260Z",
     "shell.execute_reply.started": "2024-06-26T11:23:12.990566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "finetuning_model = keras.Sequential(\n",
    "    [\n",
    "        pretraining_model.encoder,\n",
    "        layers.Dense(10),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('softmax')\n",
    "    ],\n",
    "    name=\"finetuning_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:13.000743Z",
     "iopub.status.busy": "2024-06-26T11:23:13.000420Z",
     "iopub.status.idle": "2024-06-26T11:23:13.035615Z",
     "shell.execute_reply": "2024-06-26T11:23:13.034710Z",
     "shell.execute_reply.started": "2024-06-26T11:23:13.000713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "finetuning_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:13.036962Z",
     "iopub.status.busy": "2024-06-26T11:23:13.036613Z",
     "iopub.status.idle": "2024-06-26T11:23:13.043091Z",
     "shell.execute_reply": "2024-06-26T11:23:13.042137Z",
     "shell.execute_reply.started": "2024-06-26T11:23:13.036938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:13.044547Z",
     "iopub.status.busy": "2024-06-26T11:23:13.044248Z",
     "iopub.status.idle": "2024-06-26T11:23:13.055377Z",
     "shell.execute_reply": "2024-06-26T11:23:13.054506Z",
     "shell.execute_reply.started": "2024-06-26T11:23:13.044523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TrainingPlot(keras.callbacks.Callback):\n",
    "\n",
    "  # This function is called when the training begins\n",
    "  def on_train_begin(self, logs={}):\n",
    "    # Initialize the lists for holding the logs, losses and and accuracies\n",
    "    self.losses = []\n",
    "    self.acc = []\n",
    "    self.logs = []\n",
    "    self.val_losses = []\n",
    "    self.val_acc = []\n",
    "\n",
    "  # This function is called at the end of each epoch\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    # Append the logs, losses, and accuracies to the lists\n",
    "    self.logs.append(logs)\n",
    "    self.losses.append(logs.get('loss'))\n",
    "    self.acc.append(logs.get('acc'))\n",
    "    self.val_losses.append(logs.get('val_loss'))\n",
    "    self.val_acc.append(logs.get('val_acc'))\n",
    "\n",
    "    # Before plotting ensure at least 2 epochs have passed\n",
    "    if len(self.losses) > 1:\n",
    "\n",
    "      # Clear the previous plot\n",
    "      clear_output(wait=True)\n",
    "      N = np.arange(0, len(self.losses))\n",
    "\n",
    "      # You can chose the style of your preference\n",
    "      # print(plt.style.available) to see the available options\n",
    "      plt.style.use(\"seaborn\")\n",
    "\n",
    "      # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "      plt.figure()\n",
    "      plt.plot(N, self.losses, label = \"Training Loss\")\n",
    "      plt.plot(N, self.val_losses, label = \"Val loss\")\n",
    "      plt.title(\"Train and Val Loss\")\n",
    "      plt.xlabel(\"Epoch #\")\n",
    "      plt.ylabel(\"Loss\")\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "      plt.plot(N, self.acc, label = \"Training Acc\")\n",
    "      plt.plot(N, self.val_acc, label = \"Val Acc\")\n",
    "      plt.title(\"Train and Val Accuracy \")\n",
    "      plt.xlabel(\"Epoch #\")\n",
    "      plt.ylabel(\"Accuracy\")\n",
    "      plt.legend()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:13.056405Z",
     "iopub.status.busy": "2024-06-26T11:23:13.056081Z",
     "iopub.status.idle": "2024-06-26T11:23:13.068529Z",
     "shell.execute_reply": "2024-06-26T11:23:13.067670Z",
     "shell.execute_reply.started": "2024-06-26T11:23:13.056382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_losses = TrainingPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:13.080862Z",
     "iopub.status.busy": "2024-06-26T11:23:13.080611Z",
     "iopub.status.idle": "2024-06-26T11:23:13.089443Z",
     "shell.execute_reply": "2024-06-26T11:23:13.088576Z",
     "shell.execute_reply.started": "2024-06-26T11:23:13.080840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# callbacks: ensure efficiency of the training process\n",
    "save_path = os.path.join(dir_path, '/ResNet_InceptionModule_HRNN.h5')\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\"),\n",
    "        tf.keras.callbacks.ModelCheckpoint(save_path, verbose=2, save_best_only=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='acc', factor=0.1, patience=10, min_lr=0.0000005),\n",
    "\n",
    "        plot_losses\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:13.090824Z",
     "iopub.status.busy": "2024-06-26T11:23:13.090506Z",
     "iopub.status.idle": "2024-06-26T11:23:13.108731Z",
     "shell.execute_reply": "2024-06-26T11:23:13.107633Z",
     "shell.execute_reply.started": "2024-06-26T11:23:13.090800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0005)\n",
    "finetuning_model.compile(loss='categorical_crossentropy',\n",
    "                optimizer = optimizer,\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:23:13.110546Z",
     "iopub.status.busy": "2024-06-26T11:23:13.110148Z",
     "iopub.status.idle": "2024-06-26T11:31:48.786473Z",
     "shell.execute_reply": "2024-06-26T11:31:48.785636Z",
     "shell.execute_reply.started": "2024-06-26T11:23:13.110519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "finetuning_history = finetuning_model.fit(\n",
    "    finetune_train_dataset,\n",
    "    batch_size = 64,\n",
    "    validation_data = finetune_val_dataset,\n",
    "    epochs = num_epochs,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:31:48.788601Z",
     "iopub.status.busy": "2024-06-26T11:31:48.788202Z",
     "iopub.status.idle": "2024-06-26T11:31:49.916837Z",
     "shell.execute_reply": "2024-06-26T11:31:49.915537Z",
     "shell.execute_reply.started": "2024-06-26T11:31:48.788565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.join(dir_path, '/Resnet_HRNN_Inc_SF_selfsupervised.h5')\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "\n",
    "finetuning_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T11:31:49.917750Z",
     "iopub.status.idle": "2024-06-26T11:31:49.918070Z",
     "shell.execute_reply": "2024-06-26T11:31:49.917930Z",
     "shell.execute_reply.started": "2024-06-26T11:31:49.917916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'Resnet_HRNN_Inc_SF_selfsupervised_new.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a Model Prediction Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:32:46.746950Z",
     "iopub.status.busy": "2024-06-26T11:32:46.746330Z",
     "iopub.status.idle": "2024-06-26T11:32:46.751267Z",
     "shell.execute_reply": "2024-06-26T11:32:46.750387Z",
     "shell.execute_reply.started": "2024-06-26T11:32:46.746916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:32:46.951615Z",
     "iopub.status.busy": "2024-06-26T11:32:46.951251Z",
     "iopub.status.idle": "2024-06-26T11:32:46.956668Z",
     "shell.execute_reply": "2024-06-26T11:32:46.955665Z",
     "shell.execute_reply.started": "2024-06-26T11:32:46.951585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Class Indeces Are :-->\", finetune_val_dataset.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:32:48.114249Z",
     "iopub.status.busy": "2024-06-26T11:32:48.113303Z",
     "iopub.status.idle": "2024-06-26T11:32:48.121382Z",
     "shell.execute_reply": "2024-06-26T11:32:48.120086Z",
     "shell.execute_reply.started": "2024-06-26T11:32:48.114185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_prediction(img_path, model, target_size=(IMG_DIM,IMG_DIM)):\n",
    "    # load and preprocess the image\n",
    "    img = Image.open(img_path)\n",
    "    img_array = img.resize(target_size)\n",
    "    \n",
    "    # Expand the dimension of img arry to match input shape\n",
    "    expand_dim = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    #predict\n",
    "    predictions = model.predict(expand_dim, verbose=False)\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    \n",
    "    #Map the label\n",
    "    predicted_label = next((k for k, v in finetune_val_dataset.class_indices.items() if v == predicted_class_index), None)\n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:32:48.762540Z",
     "iopub.status.busy": "2024-06-26T11:32:48.761716Z",
     "iopub.status.idle": "2024-06-26T11:32:48.774081Z",
     "shell.execute_reply": "2024-06-26T11:32:48.773252Z",
     "shell.execute_reply.started": "2024-06-26T11:32:48.762509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "finetune_val = finetune_val['ImgPath class'.split()].copy().reset_index(drop=True)\n",
    "print(\"shape_of_the_finetune_val\", finetune_val.shape)\n",
    "finetune_val.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction on the Valid Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:32:50.137008Z",
     "iopub.status.busy": "2024-06-26T11:32:50.136111Z",
     "iopub.status.idle": "2024-06-26T11:33:28.978033Z",
     "shell.execute_reply": "2024-06-26T11:33:28.977102Z",
     "shell.execute_reply.started": "2024-06-26T11:32:50.136975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "finetune_val['prediction'] = finetune_val['ImgPath'].progress_apply(lambda x:model_prediction(x, finetuning_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:34.536868Z",
     "iopub.status.busy": "2024-06-26T11:34:34.536236Z",
     "iopub.status.idle": "2024-06-26T11:34:34.548868Z",
     "shell.execute_reply": "2024-06-26T11:34:34.547893Z",
     "shell.execute_reply.started": "2024-06-26T11:34:34.536836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "finetune_val.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:36.816787Z",
     "iopub.status.busy": "2024-06-26T11:34:36.816432Z",
     "iopub.status.idle": "2024-06-26T11:34:36.822978Z",
     "shell.execute_reply": "2024-06-26T11:34:36.822168Z",
     "shell.execute_reply.started": "2024-06-26T11:34:36.816756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:37.696264Z",
     "iopub.status.busy": "2024-06-26T11:34:37.695910Z",
     "iopub.status.idle": "2024-06-26T11:34:37.701345Z",
     "shell.execute_reply": "2024-06-26T11:34:37.700272Z",
     "shell.execute_reply.started": "2024-06-26T11:34:37.696236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_true = list(finetune_val['class'])\n",
    "y_pred = list(finetune_val['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:38.735923Z",
     "iopub.status.busy": "2024-06-26T11:34:38.735595Z",
     "iopub.status.idle": "2024-06-26T11:34:38.741863Z",
     "shell.execute_reply": "2024-06-26T11:34:38.740970Z",
     "shell.execute_reply.started": "2024-06-26T11:34:38.735898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:39.617552Z",
     "iopub.status.busy": "2024-06-26T11:34:39.616805Z",
     "iopub.status.idle": "2024-06-26T11:34:39.623168Z",
     "shell.execute_reply": "2024-06-26T11:34:39.622350Z",
     "shell.execute_reply.started": "2024-06-26T11:34:39.617518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:40.194251Z",
     "iopub.status.busy": "2024-06-26T11:34:40.193874Z",
     "iopub.status.idle": "2024-06-26T11:34:40.199149Z",
     "shell.execute_reply": "2024-06-26T11:34:40.198159Z",
     "shell.execute_reply.started": "2024-06-26T11:34:40.194215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Sort the labels alphabetically\n",
    "sorted_labels = sorted(activity_map.values())\n",
    "\n",
    "# Create a dictionary to map label to index\n",
    "label_map = {label: i for i, label in enumerate(sorted_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:41.327648Z",
     "iopub.status.busy": "2024-06-26T11:34:41.326941Z",
     "iopub.status.idle": "2024-06-26T11:34:41.336613Z",
     "shell.execute_reply": "2024-06-26T11:34:41.335715Z",
     "shell.execute_reply.started": "2024-06-26T11:34:41.327609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "c_m = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:43.529375Z",
     "iopub.status.busy": "2024-06-26T11:34:43.528698Z",
     "iopub.status.idle": "2024-06-26T11:34:44.104066Z",
     "shell.execute_reply": "2024-06-26T11:34:44.103229Z",
     "shell.execute_reply.started": "2024-06-26T11:34:43.529342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setting default size of the plot\n",
    "# Setting default fontsize used in the plot\n",
    "plt.rcParams['figure.figsize'] = (10.0, 9.0)\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "# Implementing visualization of Confusion Matrix\n",
    "display_c_m = ConfusionMatrixDisplay(c_m, display_labels=sorted_labels)\n",
    "\n",
    "# Plotting Confusion Matrix\n",
    "# Setting colour map to be used\n",
    "display_c_m.plot(cmap='OrRd', xticks_rotation=25)\n",
    "# Other possible options for colour map are:\n",
    "# 'autumn_r', 'Blues', 'cool', 'Greens', 'Greys', 'PuRd', 'copper_r'\n",
    "\n",
    "# Setting fontsize for xticks and yticks\n",
    "plt.xticks(np.arange(len(label_map)), label_map.keys(), fontsize=10, rotation=25)\n",
    "plt.yticks(np.arange(len(label_map)), label_map.keys(), fontsize=10)\n",
    "\n",
    "# Giving name to the plot\n",
    "plt.title('Confusion Matrix on Validation data', fontsize=24)\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision, recall, F1-score for validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:46.424572Z",
     "iopub.status.busy": "2024-06-26T11:34:46.423928Z",
     "iopub.status.idle": "2024-06-26T11:34:46.474942Z",
     "shell.execute_reply": "2024-06-26T11:34:46.474019Z",
     "shell.execute_reply.started": "2024-06-26T11:34:46.424537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas tabulate\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# Put dictionary into DataFrame\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df_filtered = df.drop('accuracy')\n",
    "\n",
    "# In kết quả dưới dạng bảng sử dụng tabulate\n",
    "table = tabulate(df_filtered, headers='keys', tablefmt='fancy_grid')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparision against the baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T11:34:48.592945Z",
     "iopub.status.busy": "2024-06-26T11:34:48.592298Z",
     "iopub.status.idle": "2024-06-26T11:34:49.262032Z",
     "shell.execute_reply": "2024-06-26T11:34:49.261141Z",
     "shell.execute_reply.started": "2024-06-26T11:34:48.592912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The classification accuracies of the baseline and the pretraining + finetuning process:\n",
    "def plot_training_curves(pretraining_history, finetuning_history, baseline_history):\n",
    "    for metric_key, metric_name in zip([\"acc\", \"loss\"], [\"accuracy\", \"loss\"]):\n",
    "        plt.figure(figsize=(8, 5), dpi=100)\n",
    "        plt.plot(\n",
    "            baseline_history.history[f\"{metric_key}\"],\n",
    "            label=\"supervised baseline\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            pretraining_history.history[f\"p_{metric_key}\"],\n",
    "            label=\"self-supervised pretraining\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            finetuning_history.history[f\"{metric_key}\"],\n",
    "            label=\"supervised finetuning\",\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title(f\"Classification {metric_name} during training\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(f\"validation {metric_name}\")\n",
    "\n",
    "\n",
    "plot_training_curves(pretraining_history, finetuning_history, baseline_history)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868335,
     "sourceId": 5048,
     "sourceType": "competition"
    },
    {
     "datasetId": 5006073,
     "sourceId": 8411180,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
